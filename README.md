# llm-manager

Orchestrates setting up ollama docker containers and queueing requests to ensure 1 request per gpu.

Scripts aren't compiled, so run with `ts-node scripts/file.ts`
